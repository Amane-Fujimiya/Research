@article{feng2024how,
  title={How Far Are We From AGI: Are LLMs All We Need?},
  author={Feng, Tao and Jin, Chuanyang and Liu, Jingyu and Zhu, Kunlun and Tu, Haoqin and Cheng, Zirui and Lin, Guanyu and You, Jiaxuan},
  journal={arXiv preprint arXiv:2405.10313},
  year={2024},
  month={May},
  url={https://arxiv.org/abs/2405.10313}
}

@article{llm2025agi,
  title={Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches},
  author={Anonymous},
  journal={arXiv preprint arXiv:2501.03151},
  year={2025},
  month={January},
  url={https://arxiv.org/abs/2501.03151}
}

@article{agiprediction2025,
  title={AI Predicts AGI: Leveraging AGI Forecasting and Peer Review to Explore LLMs' Complex Reasoning Capabilities},
  author={Anonymous},
  journal={arXiv preprint arXiv:2412.09385},
  year={2024},
  month={December},
  url={https://arxiv.org/abs/2412.09385},
  note={Published April 2025 based on December 2024 preprint}
}

@article{zhao2023survey,
  title={Large Language Models: A Survey},
  author={Zhao, Wayne Xin and others},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024},
  month={February},
  url={https://arxiv.org/abs/2402.06196},
  note={Updated March 2025}
}

@article{apple2024reasoning,
  title={GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models},
  author={Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
  journal={Apple Machine Learning Research},
  year={2024},
  month={June},
  note={Research demonstrating fundamental barriers to generalizable reasoning in LLMs}
}

@article{nature2024agi,
  title={How close is AI to human-level intelligence? Researchers can't agree},
  author={Various},
  journal={Nature},
  year={2024},
  month={December},
  note={Discussion of AGI timelines and LLM limitations with perspectives from Yoshua Bengio and others}
}

@misc{marcus2024llm,
  title={Why LLMs Will Never Be AGI},
  author={Marcus, Gary},
  year={2024},
  month={June},
  howpublished={Online commentary},
  note={Critique of LLM capabilities and AGI expectations}
}

@misc{frewin2024llm,
  title={Why LLMs Will Never Be AGI},
  author={Frewin, Chris},
  year={2024},
  month={September},
  howpublished={Medium/Personal blog},
  note={Software engineer's perspective on LLM-to-AGI expectations}
}

@misc{ccc2025llm,
  title={LLMs Are Not the Path to General Artificial Intelligence},
  author={Bielefield, Roy},
  year={2025},
  month={May},
  publisher={Copyright Clearance Center},
  howpublished={CTO Commentary},
  note={Argues LLMs are foundations for natural language interfaces, not AGI}
}

@misc{hackernews2024embodiment,
  title={Discussion: LLMs, Embodiment, and AGI Potential},
  author={Various contributors},
  year={2024},
  howpublished={Hacker News and online forums},
  note={Community debates on whether LLMs lack necessary corporeal experience for AGI}
}

% Technical Books on AGI

@book{togelius2024agi,
  title={Artificial General Intelligence},
  author={Togelius, Julian},
  year={2024},
  publisher={MIT Press},
  series={MIT Press Essential Knowledge series},
  note={Explores technical approaches to AGI and implications for civilization}
}

@book{goertzel2007agi,
  title={Artificial General Intelligence},
  editor={Goertzel, Ben and Pennachin, Cassio},
  year={2007},
  publisher={Springer},
  series={Cognitive Technologies},
  isbn={978-3-540-23733-4},
  note={Foundational edited volume providing comprehensive AGI coverage}
}

@book{domingos2015master,
  title={The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World},
  author={Domingos, Pedro},
  year={2015},
  publisher={Basic Books},
  isbn={978-0465065707},
  note={Explores the search for a unifying machine learning algorithm that could lead to AGI}
}

@book{kurzweil2005singularity,
  title={The Singularity Is Near: When Humans Transcend Biology},
  author={Kurzweil, Ray},
  year={2005},
  publisher={Viking Press},
  isbn={978-0143037880},
  note={Influential work on AGI speculation and technological singularity}
}

@book{kurzweil1999spiritual,
  title={The Age of Spiritual Machines: When Computers Exceed Human Intelligence},
  author={Kurzweil, Ray},
  year={1999},
  publisher={Viking Press},
  isbn={978-0140282023},
  note={Earlier exploration of machine intelligence reaching human levels}
}
% Foundational Papers on Large Language Models

% The Original Transformer Architecture
@inproceedings{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  volume={30},
  pages={5998--6008},
  year={2017},
  publisher={Neural Information Processing Systems},
  url={https://arxiv.org/abs/1706.03762},
  note={NeurIPS 2017. The foundational paper introducing the Transformer architecture}
}

% BERT - Bidirectional Encoder
@inproceedings{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={4171--4186},
  year={2019},
  publisher={Association for Computational Linguistics},
  url={https://arxiv.org/abs/1810.04805},
  note={NAACL 2019. Introduced bidirectional pre-training for language representations}
}

% GPT-3 - Large-scale Few-shot Learning
@inproceedings{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  booktitle={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020},
  publisher={Neural Information Processing Systems},
  url={https://arxiv.org/abs/2005.14165},
  note={NeurIPS 2020. Introduced GPT-3 with 175B parameters demonstrating few-shot learning}
}

% Comprehensive LLM Surveys
@article{zhao2023llmsurvey,
  title={A Survey of Large Language Models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023},
  month={March},
  url={https://arxiv.org/abs/2303.18223},
  note={Comprehensive survey covering pre-training, adaptation, utilization, and evaluation of LLMs. Updated through March 2025}
}

@article{zhao2024llmsurvey2,
  title={Large Language Models: A Survey},
  author={Zhao, Wayne Xin and others},
  journal={arXiv preprint arXiv:2402.06196},
  year={2024},
  month={February},
  url={https://arxiv.org/abs/2402.06196},
  note={Reviews prominent LLM families (GPT, LLaMA, PaLM) and discusses techniques for building and augmenting LLMs}
}

% GPT-2
@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019},
  url={https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf},
  note={Introduced GPT-2, demonstrating zero-shot task transfer}
}

% GPT-1
@article{radford2018improving,
  title={Improving Language Understanding by Generative Pre-Training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  journal={OpenAI blog},
  year={2018},
  url={https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf},
  note={The original GPT paper introducing generative pre-training}
}

% T5
@article{raffel2020exploring,
  title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of Machine Learning Research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020},
  url={https://arxiv.org/abs/1910.10683},
  note={Introduced T5, treating every NLP task as a text-to-text problem}
}

% LLaMA
@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023},
  url={https://arxiv.org/abs/2302.13971},
  note={Meta's open foundation models ranging from 7B to 65B parameters}
}

% LLaMA 2
@article{touvron2023llama2,
  title={Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023},
  url={https://arxiv.org/abs/2307.09288},
  note={Updated and improved LLaMA models with better performance}
}

% PaLM
@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022},
  url={https://arxiv.org/abs/2204.02311},
  note={Google's 540B parameter model demonstrating breakthrough capabilities}
}

% InstructGPT / RLHF
@article{ouyang2022training,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022},
  url={https://arxiv.org/abs/2203.02155},
  note={Introduced RLHF for aligning language models with human preferences}
}

% Chain-of-Thought Prompting
@article{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022},
  url={https://arxiv.org/abs/2201.11903},
  note={NeurIPS 2022. Demonstrated how step-by-step reasoning improves LLM performance}
}

% Scaling Laws
@article{kaplan2020scaling,
  title={Scaling Laws for Neural Language Models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020},
  url={https://arxiv.org/abs/2001.08361},
  note={Established empirical scaling laws for language model performance}
}

% Chinchilla (Optimal Scaling)
@article{hoffmann2022training,
  title={Training Compute-Optimal Large Language Models},
  author={Hoffmann, Jordan and Borgeaud, Sebastian and Mensch, Arthur and Buchatskaya, Elena and Cai, Trevor and Rutherford, Eliza and Casas, Diego de Las and Hendricks, Lisa Anne and Welbl, Johannes and Clark, Aidan and others},
  journal={arXiv preprint arXiv:2203.15556},
  year={2022},
  url={https://arxiv.org/abs/2203.15556},
  note={Introduced Chinchilla and revised scaling laws for compute-optimal training}
}

% Constitutional AI
@article{bai2022constitutional,
  title={Constitutional AI: Harmlessness from AI Feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022},
  url={https://arxiv.org/abs/2212.08073},
  note={Anthropic's approach to AI alignment using AI-generated feedback}
}

% Papers Arguing Against LLMs Being AGI or Achieving AGI-Level Capabilities

% The Foundational Critique - Stochastic Parrots
@inproceedings{bender2021dangers,
  title={On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
  pages={610--623},
  year={2021},
  publisher={ACM},
  doi={10.1145/3442188.3445922},
  url={https://dl.acm.org/doi/10.1145/3442188.3445922},
  note={Foundational critique arguing LLMs statistically mimic text without real understanding, introducing the "stochastic parrot" metaphor}
}

% Apple Research on Reasoning Limitations
@article{mirzadeh2024gsm,
  title={GSM-Symbolic: Understanding the Limitations of Mathematical Reasoning in Large Language Models},
  author={Mirzadeh, Iman and Alizadeh, Keivan and Shahrokhi, Hooman and Tuzel, Oncel and Bengio, Samy and Farajtabar, Mehrdad},
  journal={arXiv preprint arXiv:2410.05229},
  year={2024},
  month={October},
  url={https://arxiv.org/abs/2410.05229},
  note={Demonstrates fundamental barriers to generalizable reasoning, with complete performance collapse on complex problems}
}

% Apple Research - Illusion of Thinking
@article{apple2025illusion,
  title={The Illusion of Thinking: Understanding the Strengths and Limitations of Reasoning Models via the Lens of Problem Complexity},
  author={Anonymous},
  journal={Apple Machine Learning Research},
  year={2025},
  url={https://machinelearning.apple.com/research/illusion-of-thinking},
  note={Examines Large Reasoning Models and their fundamental limitations in reasoning}
}

% Comprehensive Survey of LLM Limitations
@article{zhang2025lllms,
  title={LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models},
  author={Zhang, Yijun and others},
  journal={arXiv preprint arXiv:2505.19240},
  year={2025},
  month={May},
  url={https://arxiv.org/abs/2505.19240},
  note={Semi-automated review of 14,648 papers on LLM limitations from 2022-2024, covering reasoning failures, hallucinations, and multilingual capabilities}
}

% Primer on LLM Limitations
@article{llm2024primer,
  title={A Primer on Large Language Models and their Limitations},
  author={Sandra Johnson, David Hyland-Wood},
  journal={arXiv preprint arXiv:2412.04503},
  year={2024},
  month={December},
  url={https://arxiv.org/abs/2412.04503},
  note={Argues LLMs lack self-monitoring (phenomenal consciousness) and internal updatable models of their environment}
}

% Gary Marcus's Critiques
@misc{marcus2023elegant,
  title={Elegant and powerful new result that seriously undermines large language models},
  author={Marcus, Gary},
  year={2023},
  month={September},
  howpublished={Marcus on AI (Substack)},
  url={https://garymarcus.substack.com/p/elegant-and-powerful-new-result-that},
  note={Critique of LLM capabilities with proposed disclaimer: "All facts presented by Generative AI—even those that are true—are fictitious"}
}

@misc{marcus2025knockout,
  title={A knockout blow for LLMs?},
  author={Marcus, Gary},
  year={2025},
  month={June},
  howpublished={Marcus on AI (Substack)},
  url={https://garymarcus.substack.com/p/a-knockout-blow-for-llms},
  note={Discusses Apple research showing LLMs overanthropomorphize reasoning traces and produce incorrect answers despite correct-appearing reasoning}
}


% Formal Analysis - Communications of the ACM
@article{cacm2025knockout,
  title={A Knockout Blow for LLMs?},
  author={Gary Marcus},
  journal={Communications of the ACM},
  year={2025},
  month={June},
  url={https://cacm.acm.org/blogcacm/a-knockout-blow-for-llms/},
  note={Discusses devastating Apple research paper on LLM reasoning limitations, noting advocates are "partly conceding the blow"}
}

% Systematic Evaluation of Critical Limitations
@article{limitgen2025,
  title={Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers},
  author={Anonymous},
  journal={arXiv preprint arXiv:2507.02694},
  year={2025},
  month={July},
  url={https://arxiv.org/abs/2507.02694},
  note={Presents LimitGen benchmark and taxonomy of limitation types in AI research, evaluating LLMs' meta-cognitive capabilities}
}

@article{limgen2024,
  title={LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers},
  author={Anonymous},
  journal={arXiv preprint arXiv:2403.15529},
  year={2024},
  month={March},
  url={https://arxiv.org/abs/2403.15529},
  note={Shows summarization-specific models fail to generate limitations due to their training objectives}
}

% Philosophical and Theoretical Critiques
@misc{njii2024agi,
  title={How Close is AGI Actually? Why LLMs Alone Will Not Get us to AGI},
  author={Anonymous},
  year={2024},
  month={July},
  publisher={New Jersey Innovation Institute},
  url={https://www.njii.com/2024/07/why-llms-alone-will-not-get-us-to-agi/},
  note={Argues recent NLP advancements, while remarkable, do not constitute a path to AGI}
}

@misc{alignmentforum2025,
  title={Beware General Claims about "Generalizable Reasoning Capabilities" (of Modern AI Systems)},
  author={AI Alignment Forum},
  year={2025},
  month={June},
  howpublished={AI Alignment Forum},
  url={https://www.alignmentforum.org/posts/5uw26uDdFbFQgKzih/beware-general-claims-about-generalizable-reasoning},
  note={Discusses historical arguments from Gary Marcus and statistical learning theorists about limitations of neural network architectures}
}

% Popular Science and Commentary
@misc{towardsai2023parrots,
  title={Stochastic Parrots: A Novel Look at Large Language Models and Their Limitations},
  author={Anonymous},
  year={2023},
  month={April},
  publisher={Towards AI},
  url={https://towardsai.net/p/machine-learning/stochastic-parrots-a-novel-look-at-large-language-models-and-their-limitations},
  note={Models are not capable of true reasoning or understanding, prone to errors and biases, and perpetuate stereotypes}
}

@misc{friedman2024inference,
  title={Understanding Inference and the "Stochastic Parrot" in Large Language Models},
  author={Friedman, Dave},
  year={2024},
  month={December},
  howpublished={Personal blog (Substack)},
  url={https://davefriedman.substack.com/p/understanding-inference-and-the-stochastic},
  note={Argues LLMs are sophisticated pattern-matchers devoid of understanding, reasoning, or intentionality}
}

% Counter-Arguments and Debates
@article{lesswrong2024parrot,
  title={The Stochastic Parrot Hypothesis is debatable for the last generation of LLMs},
  author={Anonymous},
  year={2024},
  howpublished={LessWrong},
  url={https://www.lesswrong.com/posts/HxRjHq3QG8vcYy4yy/the-stochastic-parrot-hypothesis-is-debatable-for-the-last},
  note={Provides examples where LLMs fail basic inference with novel information, supporting the stochastic parrot critique}
}

% Critical Response to Stochastic Parrots
@article{baan2021slodderwetenschap,
  title={The Slodderwetenschap (Sloppy Science) of Stochastic Parrots -- A Plea for Science to NOT take the Route Advocated by Gebru and Bender},
  author={Baan, Joris},
  journal={arXiv preprint arXiv:2101.10098},
  year={2021},
  month={January},
  url={https://arxiv.org/abs/2101.10098},
  note={Counter-argument to the Stochastic Parrots paper, criticizing its methodology and ethics}
}
@misc{wang2025capabilitiesgpt5multimodalmedical,
      title={Capabilities of GPT-5 on Multimodal Medical Reasoning}, 
      author={Shansong Wang and Mingzhe Hu and Qiang Li and Mojtaba Safari and Xiaofeng Yang},
      year={2025},
      eprint={2508.08224},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2508.08224}, 
}
@misc{openai_gpt5_2025,
  author       = {{OpenAI}},
  title        = {Introducing GPT-5},
  year         = {2025},
  howpublished = {\url{https://openai.com/gpt-5/}},
  note         = {OpenAI product/technical announcement (Aug 7, 2025).}
}

@misc{openai_inside_gpt5_2025,
  author       = {{OpenAI}},
  title        = {Inside GPT-5 for Work},
  year         = {2025},
  howpublished = {\url{https://cdn.openai.com/pdf/inside-gpt-5-for-work.pdf}},
  note         = {Technical overview / PDF from OpenAI.}
}
@misc{guo_deepseek_r1_2025,
  author       = {D. Guo and others},
  title        = {DeepSeek-R1: Incentivizing Reasoning Capability in LLMs},
  year         = {2025},
  howpublished = {arXiv preprint arXiv:2501.12948},
  url          = {https://arxiv.org/abs/2501.12948},
  note         = {Introduces DeepSeek-R1 and DeepSeek-R1-Zero; RL-based reasoning training.}
}

@misc{deepseek_hf_2025,
  author       = {{DeepSeek AI / Hugging Face}},
  title        = {deepseek-ai/DeepSeek-R1 (model card)},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/deepseek-ai/DeepSeek-R1}},
  note         = {Model page and downloads (weights / details).}
}
@misc{anthropic_claude3_modelcard_2024,
  author       = {{Anthropic}},
  title        = {The Claude 3 Model Family: Opus, Sonnet, Haiku (Model Card)},
  year         = {2024},
  howpublished = {\url{https://www-cdn.anthropic.com/.../Model_Card_Claude_3.pdf}},
  note         = {Official Claude 3 model card (PDF) from Anthropic.}
}

@misc{anthropic_tracing_thoughts_2025,
  author       = {{Anthropic Research}},
  title        = {Tracing the Thoughts of a Large Language Model},
  year         = {2025},
  howpublished = {\url{https://www.anthropic.com/research/tracing-thoughts-language-model}},
  note         = {Research blog/papers on interpretability and internal features.}
}
@article{touvron_llama_2023,
  author    = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timoth{\'e}e Lacroix and Baptiste Rozi{\`e}re and Naman Goyal and Eric Hambro and Faisal Azhar and Aur{\'e}lien Rodriguez and Armand Joulin and {\'E}douard Grave and Guillaume Lample},
  title     = {LLaMA: Open and Efficient Foundation Language Models},
  journal   = {arXiv preprint arXiv:2302.13971},
  year      = {2023},
  url       = {https://arxiv.org/abs/2302.13971}
}
@inproceedings{chowdhery_palm_2022,
  author    = {Amitabh Chowdhery and others},
  title     = {PaLM: Scaling Language Modeling with Pathways},
  year      = {2022},
  howpublished = {arXiv preprint arXiv:2204.02311},
  url       = {https://arxiv.org/abs/2204.02311}
}

@misc{anil_palm2_2023,
  author    = {R. Anil and others},
  title     = {PaLM 2 Technical Report},
  year      = {2023},
  howpublished = {arXiv preprint arXiv:2305.10403},
  url       = {https://arxiv.org/abs/2305.10403}
}
@misc{jiang_mistral7b_2023,
  author    = {A. Q. Jiang and others},
  title     = {Mistral 7B},
  year      = {2023},
  howpublished = {arXiv preprint arXiv:2310.06825},
  url       = {https://arxiv.org/abs/2310.06825},
  note      = {Mistral AI release (7B model) and technical description.}
}

@misc{mistral_blog_2023,
  author    = {{Mistral AI}},
  title     = {Announcing Mistral 7B},
  year      = {2023},
  howpublished = {\url{https://mistral.ai/news/announcing-mistral-7b}},
  note      = {Official release blog and model card.}
}

@book{bostrom_superintelligence_2014,
  author    = {Nick Bostrom},
  title     = {Superintelligence: Paths, Dangers, Strategies},
  publisher = {Oxford University Press},
  year      = {2014},
  isbn      = {978-0199678112}
}

@book{barrat_our_final_invention_2013,
  author    = {James Barrat},
  title     = {Our Final Invention: Artificial Intelligence and the End of the Human Era},
  publisher = {Thomas Dunne Books},
  year      = {2013},
  isbn      = {978-0-312-62237-4}
}

@book{birch_edge_of_sentience_2024,
  author    = {Jonathan Birch},
  title     = {The Edge of Sentience: Risk and Precaution in Humans, Other Animals, and AI},
  publisher = {Oxford University Press},
  year      = {2024},
  isbn      = {978-0-19-287042-1}
}

@book{yudkowsky_soares_anyone_builds_2025,
  author    = {Eliezer Yudkowsky and Nate Soares},
  title     = {If Anyone Builds It, Everyone Dies: Why Superhuman AI Would Kill Us All},
  publisher = {Hachette Book Group},
  year      = {2025},
  isbn      = {9780316595643}
}

@book{hao_empire_of_ai_2025,
  author    = {Karen Hao},
  title     = {Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI},
  publisher = {Penguin Press},
  year      = {2025},
  isbn      = {978-0593657508}
}

@article{cui_risk_taxonomy_mitigation_2024,
  author    = {Tianyu Cui and Yanling Wang and Chuanpu Fu and Yong Xiao and Sijia Li and Xinhao Deng and Yunpeng Liu and Qinglin Zhang and Ziyi Qiu and Peiyang Li and Zhixing Tan and Junwu Xiong and Xinyu Kong and Zujie Wen and Ke Xu and Qi Li},
  title     = {Risk Taxonomy, Mitigation, and Assessment Benchmarks of Large Language Model Systems},
  journal   = {arXiv preprint},
  year      = {2024},
  howpublished = {arXiv:2401.05778},
  url       = {https://arxiv.org/abs/2401.05778}
}

@article{bucknall_dori_hacohen_current_near_term_2022,
  author    = {Benjamin S. Bucknall and Shiri Dori-Hacohen},
  title     = {Current and Near-Term AI as a Potential Existential Risk Factor},
  journal   = {arXiv preprint},
  year      = {2022},
  howpublished = {arXiv:2209.10604},
  url       = {https://arxiv.org/abs/2209.10604}
}

@article{faroldi_risk_and_agency_2024,
  author    = {Federico L. G. Faroldi},
  title     = {Risk and Artificial General Intelligence},
  journal   = {AI \& Society},
  volume    = {40},
  number    = {4},
  pages     = {2541--2549},
  year      = {2025},
  doi       = {10.1007/s00146-024-02004-z}
}

@article{koessler_schuett_2023_risk_assessment_agi_companies,
  author    = {Leonie Koessler and Jonas Schuett},
  title     = {Risk assessment at AGI companies: A review of popular risk assessment techniques from other safety-critical industries},
  journal   = {arXiv preprint},
  year      = {2023},
  howpublished = {arXiv:2307.08823},
  url       = {https://arXiv.org/abs/2307.08823}
}
@article{bubeck_sparks_agi_2023,
  author    = {S{\'e}bastien Bubeck and Varun Chandrasekaran and Ronen Eldan and Johannes Gehrke and Eric Horvitz and Ece Kamar and Peter Lee and Yin Tat Lee and Yuanzhi Li and Scott Lundberg and Harsha Nori and Hamid Palangi and Marco Tulio Ribeiro and Yi Zhang},
  title     = {Sparks of Artificial General Intelligence: Early experiments with GPT-4},
  journal   = {arXiv preprint},
  year      = {2023},
  howpublished = {arXiv:2303.12712},
  url       = {https://arxiv.org/abs/2303.12712}
}

@article{mumuni_survey_llms_for_agi_2025,
  author       = {Alhassan Mumuni and Fuseini Mumuni},
  title        = {Large Language Models for Artificial General Intelligence: A Survey of Foundational Principles and Approaches},
  journal      = {arXiv preprint},
  year         = {2025},
  howpublished = {arXiv:2501.03151},
  url           = {https://arxiv.org/abs/2501.03151}
}

@article{shang_ai_native_memory_2024,
  author       = {Jingbo Shang and Zai Zheng and Jiale Wei and Xiang Ying and Felix Tao and Mindverse Team},
  title        = {AI-native Memory: A Pathway from LLMs Towards AGI},
  journal      = {arXiv preprint},
  year         = {2024},
  howpublished = {arXiv:2406.18312},
  url           = {https://arxiv.org/abs/2406.18312}
}

@article{llm_cognitive_capabilities_evidence_2024,
  author    = {David Ilić,  Gilles E. Gignac},
  title     = {Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?},
  journal   = {Intelligence},
  volume    = {106},
  pages     = {101858},
  year      = {2024},
  doi       = {10.1016/j.intell.2024.101858},
  url       = {https://doi.org/10.1016/j.intell.2024.101858}
}

@article{goertzel_generative_ai_vs_agi_2023,
  author    = {Ben Goertzel},
  title     = {Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs},
  journal   = {arXiv preprint},
  year      = {2023},
  howpublished = {arXiv:2309.10371},
  url         = {https://arxiv.org/abs/2309.10371}
}



@article{llms_assessment_for_singularity_2025,
  author    = {Ryunosuke Ishizaki, Mahito Sugiyama},
  title     = {Large language models: assessment for singularity},
  journal   = {AI \& Society},
  year      = {2025},
  note      = {Open access},
  url       = {https://link.springer.com/article/10.1007/s00146-025-02271-4}
}

@article{altmeyer_position_stop_unsci_agi_claims_2024,
  author    = {Patrick Altmeyer and Andrew M. Demetriou and Antony Bartlett and Cynthia C. S. Liem},
  title     = {Position: Stop Making Unscientific AGI Performance Claims},
  journal   = {arXiv preprint},
  year      = {2024},
  howpublished = {arXiv:2402.03962},
  url         = {https://arxiv.org/abs/2402.03962}
}
@article{turing1950computing,
  author = {Turing, Alan M.},
  title = {Computing Machinery and Intelligence},
  journal = {Mind},
  volume = {59},
  number = {236},
  pages = {433--460},
  year = {1950},
  note = {Classic proposal of the ``Imitation Game'' (Turing Test).}
}

@misc{dartmouth1955proposal,
  author = {McCarthy, John and Minsky, Marvin and Rochester, Nathaniel and Shannon, Claude E.},
  title = {A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence},
  howpublished = {Technical proposal (Aug 31, 1955); reprinted/retrospective in AI Magazine 2006},
  year = {1955},
  note = {Founding proposal that coined the term ``artificial intelligence''.}
}

@book{russell2010aima,
  author = {Russell, Stuart and Norvig, Peter},
  title = {Artificial Intelligence: A Modern Approach},
  edition = {3},
  publisher = {Prentice Hall},
  year = {2010},
  note = {Standard textbook that frames AI via agents and a taxonomy of definitions/goals.}
}

@misc{stanford2018ai,
  author = {{Stanford Encyclopedia of Philosophy}},
  title = {Artificial Intelligence},
  howpublished = {\url{https://plato.stanford.edu/entries/artificial-intelligence/}},
  year = {2018},
  note = {A well-rounded survey of history, proposed definitions, and philosophy-of-AI debates.}
}

@book{penrose1989emperor,
  author = {Penrose, Roger},
  title = {The Emperor's New Mind: Concerning Computers, Minds, and the Laws of Physics},
  publisher = {Oxford University Press},
  year = {1989},
  note = {Philosophical argument against the possibility of full computational emulation of human consciousness.}
}


@article{floridi2004philosophy,
  author = {Floridi, Luciano},
  title = {From the Philosophy of Information to an Information Ethics},
  journal = {Philosophy \& Technology},
  year = {2004},
  note = {Places AI debates within a broader `information' philosophical framework.}
}
@book{mccarthy1987general,
  author = {McCarthy, John},
  title = {Generality in Artificial Intelligence},
  publisher = {Communications of the ACM},
  year = {1987},
  note = {A key voice emphasizing the distinction between domain-limited AI ('weak') and the aspiration toward general AI ('strong').}
}
@mastersthesis{Oygarden2019,
  author       = {Øygarden, Even},
  title        = {What is Intelligence? A Proposed Framework of Four Different Concepts of Intelligence},
  school       = {University of Agder},
  year         = {2019},
  type         = {Master’s thesis},
  supervisor   = {Einar Duenger Bøhn},
  url          = {https://uia.brage.unit.no/uia-xmlui/bitstream/handle/11250/2632728/%C3%98ygarden%2C%20Even.pdf?sequence=1},
}