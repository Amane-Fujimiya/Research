{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "This page includes the list of projects, researches in questions,\n",
        "proposals and ideas that is of consideration in the future. Most of them\n",
        "are incomplete, and are welcoming adoption from certain collaboration if\n",
        "requested or encouraged. While this is not always up-to-date (as I have\n",
        "an internal organization structure), it should be, most of the time\n",
        "adequate. For now, let us construct the main foundation on what are we\n",
        "going to do with the short-term papers and not the long-term, 2.5 years\n",
        "waitlist papers.\n",
        "\n",
        "## List of interesting topics\n",
        "\n",
        "For now, here are some of the paper topics:\n",
        "\n",
        "1.  **Double descent: a review** (review, reference): A reference and\n",
        "    review paper talking about double descent. Including effort to\n",
        "    formalize the definition of it.\n",
        "2.  **Interpreting double descent in polynomial via density estimation**\n",
        "    (original, theory): A fairly light and theoretical paper on the toy\n",
        "    model description of polynomial model and different interpretation.\n",
        "3.  **Double descent on support vector machine and polynomial models on\n",
        "    binary classification - an analysis** (experimental, theory): A both\n",
        "    theory and experimental paper.\n",
        "4.  **PINNs and double descent** (experimental): An experimental on\n",
        "    PINNs and how to identify double descent on it.\n",
        "5.  **Classical learning theory and future** (original, review,\n",
        "    experiments).\n",
        "6.  **A review of model structures in machine learning and theoretical\n",
        "    machine learning** (theoretical, review, reference): A reference\n",
        "    paper on the concept of models in machine learning, their\n",
        "    structures, flavour, consideration, and thereof.\n",
        "7.  **Different treatment of machine learning - an analysis** (review,\n",
        "    reference, original): A paper on the different treatment of machine\n",
        "    learning, from different lens and scale, and how do they fit\n",
        "    together (categorical machine learning for example).\n",
        "8.  **Reuniting the neural network framework using partial category\n",
        "    theory** (original, theory): Using the proposed categorical machine\n",
        "    learning or neural network to consider reuniting different\n",
        "    architecture together under the same framework.\n",
        "9.  **On the capacity and capability of neural networks** (review,\n",
        "    original): A paper analysing the capacity and capability of neural\n",
        "    networks on various task and setting thereof, and so forth,\n",
        "    considering different structures.\n",
        "10. **Machine learning from a mathematical modelling view** (review,\n",
        "    original): Proposing a modelling theoretic, internal state\n",
        "    interpretation to machine learning.\n",
        "11. **The analysis of statistical physics on machine learning** (review,\n",
        "    original): Setting up a review work on how statistical physics is\n",
        "    related to machine learning, where is it failing and what constitute\n",
        "    the failure.\n",
        "12. **Classical model into neural network architecture - an analysis**\n",
        "    (original, theoretical): An attempt to attack and formalize\n",
        "    classical models into neural network theoretic (unit-wise approach\n",
        "    of neuronal unit) to classical models, hence gauging their\n",
        "    capability.\n",
        "13. **Unsolved problems in theoretical machine learning** (original,\n",
        "    review): A work in review of different interpretations and problems\n",
        "    residing the current framework of machine learning.\n",
        "14. **Differential equations and machine learning - interpreting machine\n",
        "    learning system using differential equations** (original, theory):\n",
        "    An attempt to express ML systems in terms of differential equations,\n",
        "    just as the differential model.\n",
        "15. **LLM cannot be AGI** - the kind of paper.\n",
        "16. **Neural network learning equals mathematical model structural\n",
        "    approximation** (original, theory, experiment).\n",
        "17. **Concentration inequalities in theoretical machine learning for\n",
        "    beginner**.\n",
        "18. **Structural addition in machine learning - an analysis**.\n",
        "19. **Component and structural realization of large language model and\n",
        "    why they are not intelligent** - just to prove that LLM is not,\n",
        "    well, intelligent and again, won’t ever be AGI.\n",
        "20. **Hallucination is bias-variance tradeoff** - we just, well, connect\n",
        "    it to them.\n",
        "21. **Visualization of neural network operation and layer theoretic**.\n",
        "22. **Time-sensitive** processing network - something that look like an\n",
        "    operational system in the inner units of the neural network, so\n",
        "    yeah.\n",
        "23. **Always running neural network**. Mimicking a network to well,\n",
        "    always run and is not static.\n",
        "24. **Visualizing dynamics and bias-variance plus double descent**.\n",
        "25. **Information theoretic interpretation of machine learning\n",
        "    framework**.\n",
        "26. **Randomized neural network architecture on permutations** (theory,\n",
        "    experiment, original) - just a way to do such analysis.\n",
        "27. **`MultiNet` - A new multidirectional structure of neural network\n",
        "    formalism** (original, experimentation) - just a generalization of\n",
        "    what I observed of neural network structure in general. Will have to\n",
        "    base on existing facility, can’t do anything else.\n",
        "28. **Theoretical explanation for Neural Scaling Law** (original,\n",
        "    theoretical) - Just an attempt to solve the neural scaling law.\n",
        "\n",
        "For now, they are short papers for machine learning. On physics, well.\n",
        "\n",
        "1.  **The theory of Raman Spectroscopy** (review, reference): On the\n",
        "    theory of Raman spectroscopy on itself, different interpretation,\n",
        "    history, approaches, and problems. That is it for now. More is in\n",
        "    the `PDF` file itself, which is listed there for reasons."
      ],
      "id": "594a2e35-313b-45ad-928f-78f338384f65"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}